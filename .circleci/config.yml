version: 2.1
orbs:
  compass: atlassian-labs/compass@0.1.2
  maven: circleci/maven@1.3.0
  cypress: cypress-io/cypress@2.2.0
          
executors:
  with-chrome:
    docker:
      - image: 'cypress/browsers:node14.16.0-chrome90-ff88'
  base:
    docker:
      - image: cimg/deploy:2022.07
  jdk17:
    docker:
      - image: cimg/openjdk:17.0.3
    
    resource_class: xlarge
  python38:
    docker:
      - image: cimg/python:3.8


jobs:
  python-checkstyle:
    executor: python38
    steps:
      - checkout
      - run: pip install pylint
      - run:
          name: Lint Python
          command: pylint --rcfile=./.pylintrc ./src/*/*.py

  python-test:
    executor: python38
    steps:
      - checkout
      - run: mkdir test-reports
      - run:
          name: Test Python Services
          command: |
            for SERVICE in "contacts" "userservice"; do
              echo "testing $SERVICE..."
              # save current working dir to memory and cd to src/$SERVICE
              pushd src/$SERVICE
                python3 -m venv $HOME/venv-$SERVICE
                source $HOME/venv-$SERVICE/bin/activate
                pip install --upgrade pip
                pip install -r requirements.txt
                python -m pytest --junit-xml=../../test-reports/report-${SERVICE}.xml -v -p no:warnings
                deactivate
              # return to previously saved path
              popd
            done
      - store_test_results:
          path: test-reports
      - store_artifacts:
          path: test-reports

  java-checkstyle:
    executor: jdk17
    steps:
      - checkout
      - maven/with_cache:  
          verify_dependencies: false       
          steps: 
          - run: ./mvnw checkstyle:check


  java-test-and-code-cov:
    executor: jdk17
    steps:
      - checkout
      - run: mkdir test-reports
      - run: mvn help:effective-pom > /tmp/zpom.xml
      - restore_cache:
          keys:
            - v1-mvn-full-{{ checksum "/tmp/zpom.xml" }}
            - v1-mvn-full-
      - run: mvn dependency:go-offline
      - save_cache:
          key: v1-mvn-full-{{ checksum "/tmp/zpom.xml" }}
          paths:
            - ~/.m2
      - run: |
          ./mvnw test
          for SERVICE in "balancereader" "ledgerwriter" "transactionhistory"; do
          echo "checking $SERVICE..."
          # save current working dir to memory and cd to src/$SERVICE
          pushd src/$SERVICE
          ../../mvnw jacoco:report
          echo "Coverage for $SERVICE:"
          awk -F, \
          '{ instructions += $4 + $5; covered += $5 } END \
          { print covered, "/", instructions, " instructions covered"; \
          print int(100*covered/instructions), "% covered" }' \
          target/site/jacoco/jacoco.csv
          cp target/surefire-reports/*.xml ../../test-reports
          # return to previously saved path
          popd
          done
      - store_test_results:
          path: test-reports
      - store_artifacts:
          path: test-reports

  skaffold-build-push:
      executor: jdk17
      steps:
        - checkout
        - run: |
            curl -Lo skaffold https://storage.googleapis.com/skaffold/releases/latest/skaffold-linux-amd64 && \
            sudo install skaffold /usr/local/bin/
        - load-dockerhub-credentials    
        - setup_remote_docker:
            docker_layer_caching: true
        - run: mvn help:effective-pom > /tmp/zpom.xml
        - restore_cache:
            keys:
              - v1-mvn-full-{{ checksum "/tmp/zpom.xml" }}
              - v1-mvn-full-
        - run: |
            # seems like skaffold jib needs a eird kick, hit me locally, passes on second run
            ./mvnw jib:_skaffold-fail-if-jib-out-of-date -Djib.requiredVersion=1.4.0 --projects src/ledgerwriter --also-make jib:_skaffold-files-v2 --quiet --batch-mode
            mkdir output
            skaffold build --build-concurrency=4 --tag=build$(git rev-parse HEAD:src) --default-repo=docker.nexus.cera.circleci-labs.com --file-output=output/tags.json
            ls /tmp/
        - persist_to_workspace:
            root: output
            paths: [ 'tags.json' ]
 

  deploy:
    executor: base
    parameters:
      environment:
        type: string
        default: dev
        description: Environment suffix used by namesapce and SA account name.
    steps:
      - checkout
      - load-cluster-credentials
      - run: echo "Now using ${K8S_USER}@${K8S_NAMESPACE}"
      - run: |
          sudo apt update && sudo apt install kubectl -y
          kubectl config view
          kubectl get serviceaccounts -n ${K8S_NAMESPACE}
      # temp whike using ecr
      - run: | 
          curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
          unzip awscliv2.zip
          sudo ./aws/install
      - load-dockerhub-credentials
  
      - attach_workspace:
          at: output
      - run: 
          name: Deploy BoA
          command: |
            curl -Lo skaffold https://storage.googleapis.com/skaffold/releases/latest/skaffold-linux-amd64 && \
            sudo install skaffold /usr/local/bin/
            skaffold deploy --default-repo=docker.nexus.cera.circleci-labs.com --namespace=${K8S_NAMESPACE} --build-artifacts=output/tags.json
      - run:
          name: Wait for deployment
          command: |
            kubectl wait deployment -n ${K8S_NAMESPACE} frontend --for condition=Available=True --timeout=90s
      - run: 
          name: Print Frontend URL
          command: kubectl get service frontend -n ${K8S_NAMESPACE} | awk '{print $4}'
  e2e:
    executor: with-chrome
    steps:
      - checkout
      - run: 
          name: Run Cypress Tests
          command: |
            cd ui-tests
            npx cypress run \
            --config baseUrl=https://dev.cera.circleci-labs.com \
            --browser firefox \
            --reporter junit \
            --reporter-options "mochaFile=results/my-test-output-[hash].xml"
      - store_test_results:
          path: ui-tests/results
      - store_artifacts:
          path: ui-tests/cypress/videos
      - store_artifacts:
          path: ui-tests/cypress/screenshots    
   
workflows:
  main:
    jobs:
      - java-checkstyle
      - java-test-and-code-cov
      - python-checkstyle
      - python-test
      - skaffold-build-push:
          requires: [ python-test, java-test-and-code-cov ]
          context: cera-vault-oidc
      - deploy:
          name: Deploy Dev
          requires: [ skaffold-build-push ]
          context: [ compass-integration-bank-of-aion, cera-vault-oidc ]
          post-steps:
            - compass/notify_deployment:
                token_name: COMPASS_CCI_TOKEN
                environment_type: development
      - e2e:
          requires: [ Deploy Dev ]
      - deploy:
          name: Deploy Production
          requires: [ e2e ]
          context: [ compass-integration-bank-of-aion, cera-vault-oidc-prod ]
          filters:
            branches:
              only: [ main ]
          post-steps:
            - compass/notify_deployment:
                token_name: COMPASS_CCI_TOKEN
                environment_type: production
                environment: CERA-Cluster-Namer-Prod


commands:
  load-cluster-credentials:
  # This command uses the assigned context to hydrate a kubeconfig from the given service account.
  # These values are automatically injected into the 2 app contexts by the `reference-architecture` project
    steps:
      - install-vault
      - run:
          command: |
            source .circleci/vault/cluster
            echo ${K8S_CERT} | base64 -d > ca.crt
            kubectl config set-cluster ${K8S_CLUSTER} --server=${K8S_URL} --certificate-authority=ca.crt
            export DECODED_TOKEN=$(echo ${K8S_TOKEN} | base64 -d) #kubectl prints an encoded value, MUST decode it to work.
            kubectl config set-credentials ${K8S_USER} --token=${DECODED_TOKEN}
            kubectl config set-context default --user=${K8S_USER}  --cluster=${K8S_CLUSTER} --namespace ${K8S_NAMESPACE}
            kubectl config use-context default
            #export for other steps
            bash .circleci/vault/cluster.export
          name: Use K8s token & cert to create kubeconfig.

  load-dockerhub-credentials:
    steps:
      - install-vault
      - run:
          name: authenticate-and-interact
          command: |
            # use the OpenID Connect token to obtain username password
            source .circleci/vault/dockerhub # read file agent created from secrets
            echo "export NEXUS_USER=${DOCKER_LOGIN}" >> $BASH_ENV
            echo "export NEXUS_PASSWORD=${DOCKER_PWD}" >> $BASH_ENV
            echo "${DOCKER_PWD}" | docker login --username ${DOCKER_LOGIN} --password-stdin docker.nexus.cera.circleci-labs.com

  install-vault:
    steps:
      - run:
          name: install vault agent (if not present)
          command: |
            vault -h && exit 0 || echo "Installing vault"
            #only runs if vault command avbove failed
            pushd /tmp
            wget https://releases.hashicorp.com/vault/1.12.2/vault_1.12.2_linux_amd64.zip
            unzip vault_1.12.2_linux_amd64.zip
            sudo mv vault /usr/local/bin        
            vault -h    
            popd
            echo $CIRCLE_OIDC_TOKEN > .circleci/vault/token.json
            vault agent -config=.circleci/vault/agent.hcl

# VS Code Extension Version: 1.0.0

# VS Code Extension Version: 1.0.0

# VS Code Extension Version: 1.1.1
